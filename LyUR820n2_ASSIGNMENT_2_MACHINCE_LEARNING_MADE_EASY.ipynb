{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LyUR820n2_ASSIGNMENT_2_MACHINCE_LEARNING_MADE_EASY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbud_VembfGr"
   },
   "source": [
    " <img src = \"tete.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JbvVDwMPTwt9",
    "outputId": "9aa47577-d310-49f1-8a80-a55d2e3f6221"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlkIAEBRcbgy"
   },
   "source": [
    "\n",
    "# Lab Questions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCWoJc0Sy6fA"
   },
   "source": [
    "**1. In your own words, briefly define overfitting, underfitting, good fit, regularization. Provide a sketch indicating a sample data set, an over-fit curve, an under-fit curve and a good fit curve.** (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxTteoZky_RL"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.   Overfitting is a machine learning scenario that the model perform very well on the training data (which mean the model give the very good metrics evaluation: error here is quite equal to zero) and fail to perfom also in the data that it never seen before (the model is failing to cary out the good performance during the testing). The error compuation in the testing used to be very high because the model was just memorizing the train data.\n",
    "\n",
    "2. Underfitting is the machine learning situation that caraterize a model that is not able to learn well (find relation between the variable and the responde) during the training using the train data and do also the same during the test with the data that it never seen before (test data). Note that for this case the situation the error is high for the training step such as the testinh step and the metric evaluation are not good (small accuracy).  \n",
    "\n",
    "3. Good fit is a qualification that we give to a machine learning model that is able to perform well on the train data and do also the same with the test data, we say that the model is learning well the patern in the data. Note that the error for this case is minimize for both cases (training and testing  step).\n",
    "4. Regularization refert to the methodes that are used in a way to minimize the ajusted lost function and the aim is to avoid such problems as underfitting and overfitting in a machine learning process. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"question_1_fig.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqgLO9aCzAl_"
   },
   "source": [
    "**2. Where can we introduce noise into a network? Why there? Can we introduce noise in multiple areas of a network? Why or why not?** (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzX4GTQPzE1Z"
   },
   "source": [
    "\n",
    "*Write answer here*\n",
    "\n",
    "1. According  to Hinton, noise can be added directly on the output layer. We add there because it will help the network to break up partterns that are not significant and avoid memorizing (was called \"conspiracies\" by Hinton). The aim is to reduces overfitting.\n",
    "Note that, we can also add noise directly to the input data, the activation function, the weights, or in the labels of the target variable.\n",
    "\n",
    "2. From what we said at the first part of this question, there are many way to add noise in the network, which mean that we can add noise in multiple area in the network. Since we can add noise in the input data itself, the activation function and the output leyer themselves in a way to avoid averfitting. But note that for the same neural neural network we don't need to add those noise at different places at the same time (no we can't add in all those places for the same neural network that we are training). Since the aim is to help the machine to not memorize the data is enough to just do it at one place. \n",
    "Adding everywhere will can be seen as a problem by the network because the value (data) will be changing every time and we can also lost the general description of our data by something that has no meaning (noise).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgmw_aoqzF5r"
   },
   "source": [
    "**3. What are the most common ways to prevent overfitting and provide an example of each.** (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf-mLwvP-wen"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "The most common way to avoid overfitting are:\n",
    "1. Getting more training data.\n",
    "* The example is the generation of the new data using the avalibles (create others images from the original image).\n",
    "2. Reducing the capacity of the network.\n",
    "* Randomly revome different subset of the network like the example given by Geoff Hinton, or reduise the edge which mean use the non dense network.\n",
    "3. Adding weight regularization.\n",
    "* Add some constraint that will help to take only the norm of the weight so that the distribution will be good (same range), the practical case is to use L1 penality regularization. Another way to reduise the parameter is to make sure that some weigths are the same or we can also asign some of them to zero.\n",
    "4. Adding dropout,\n",
    "* Add some dropped leyers that will disconnect (some nodes) during the model training. A clear case is the definition of a set of probability and design the network so that when the output of a node is equal that node can just be remove on the system (it also help to reduce complexity of the network). \n",
    "this is a concrete exemple of dropout describe by the note \"The tellers kept changing and I asked one of them why. He said he didn’t know but they got moved around a lot. I figured it must be because it would require cooperation between employees to successfully defraud the bank\".\n",
    "\n",
    "5. Addition of noise to the input data,\n",
    "* Generate some random data that will help to reduce correlation between the variables. Like creating a rando signal an add it to the signal that we are using as data when we are dealing with the song, create some random word also for the case of work prediction. \n",
    "we also do it for the case where the set of data is small, we generate some random value to add the sample of our trainin.\n",
    "6. Feature selection.\n",
    "The clear example of this procedure is application or beruta algorithm. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kndUKqi0zSTb"
   },
   "source": [
    "**4. What is the cost added proportional to in L1 and in L2 regularization?** (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfYJs8STzWbj"
   },
   "source": [
    "*Write answer here*\n",
    "1. The cost of adding L1 regularization is proportional to the absolute value of the weights coefficients (which mean the L1 norm of the weight).\n",
    "2. The cost of adding L2 reglarization is proportional to the square of the value of the weights coefficients (i.e. to what is called the \"L2 norm\" of the weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lO5O3ULzXj_"
   },
   "source": [
    "**5. Describe the steps involved to find the right model size for a given set of data.** (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY-okHRSzcqA"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "Base on the no free lunch theorem and on what is describe above we can descripe the following steps as the way to find the righ size model for a given data.\n",
    "1.  **Analyse and Understand the data**\n",
    "\n",
    "The aim of this fist step is to get contact with the data, visualize and try to preprocess the data to make sure that they are usesable. understand the data here mean try to determine the problem that we are going to solve using those data. After the process of verification of every missing part on the data, we move to the second step with is separate the data.\n",
    "\n",
    "2. **Separation of the data**\n",
    "\n",
    "In this step we label our data according to the problem that we have to solve, and after that we separated those data into two different parts: one part for the training (the biggest part, and can be 70, 75, or 80% of the total) and another part will be use for the test (we mean the reminder 30, 25, or 20% of the total data). The next step is to create our model.\n",
    "\n",
    "3. **Disign and evaluation of neural network model**\n",
    "\n",
    "Since there is no exact way to difine directly the good model, we start this part by creating the easy model as possible (few layers and parameters) and we evaluate the performance of the model by recording different metrics evaluation (accuracy, error ) and we try to optimize those metrics. In case there are not better we try other architecture by adding parameters as layers and nodes. After adding those parameters we evaluate again the model, recording different metrics and evaluate the performance compare to what we had before. Repeat this process until we obtain some better parameters which mean the optimize values (when the loss error of the model is deacrising considerably). Also note that we can face the some problems as overfitting and underfitting, and in such case we use the listed methodes above to avoid or prevent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDD1tQeozdyN"
   },
   "source": [
    "**6. What is meant by bias in a network? What happens when a model has a High Bias? What is this an example of (overfitting or underfitting)?** (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gftW_kmTziA9"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "1. The bias in the network means that the network is definding it result or predictions more base on a certain criteria (specifict variable than the others). Neural network bias is a constant that influences the outcome of the features and weights. We used to modify the result.\n",
    "\n",
    "2. Based on the level of biasness the model can give a total différent result instead of what we expecting,  The models can change the activation function to either the positive or negative side. The model underfit when it has high bias becauce it will not be able to learn well even on the train data, the model has the problem on mapping the input and the output.\n",
    "\n",
    "3. As we have mentioned the bias is more related to underfitting. (high bias will bring the case of underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-aTiWJ_znSx"
   },
   "source": [
    "**7. What is meant by “variance” in a network? What happens when a model has High Variance? What is this an example of (overfitting or underfitting)?** (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TEOtSPez2Qv"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "1. The variance is the network is explain by the diference between the real value and the predicted value by the network. Note that the variance is valuate on the test data which mean after the training process.\n",
    "2. Since we compute the variance on the testing data, when the diference between the predicted value and the real values are very high which characterize the case of high variance, we can say that we are facing a case of overfitting. because the model learn well during the training but which is not the case on the testing data.\n",
    "3. This is and example of overfitting (correspond to high variance of the model: poor prediction on the unseen data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcAaCHPXzrh8"
   },
   "source": [
    "**8. Read the following article: https://www.theregister.com/2020/07/01/mit_dataset_removed/\n",
    "Describe a scenario in which biased datasets and models could affect your life negatively. Describe a scenario that does NOT affect your life but could have a negative impact on someone else’s life. What factors must be monitored to prevent biased datasets and models from exhibiting unexpected negative behaviour?** (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIKdd0ghz00x"
   },
   "source": [
    "*Write answer here*\n",
    "\n",
    "In this part, we describe the situations based on the reading of the article whose link is given in the questionnaire. \n",
    "\n",
    "1. In one part of the article Vinay Prabhu, chief scientist at UnifyID, and Abeba Birhane, a PhD student, report on the impressive database of images they discovered with very disappointing labels. The database uses very harsh words (rasist and insulting to the minority that are blacks and Asians) to describe certain images, such as images of black skinned men that carry the same labels as monkeys, also sensitive images of genitals that are used for these models.  In more than 80% of this article the author reveals the qualities of the data that the automatic network models are trained on and given the wrong way the data is labeled, based on the use of racist words, insults and other offenses described, these networks can affect my life negatively by seeing my picture of a black person wearing the same labels as the monkeys. Because of this mislabeling a man was arrested by the police for an unconsidered crime. A network trained on this quality of data has all the power to change our lives negatively like the man who was arrested by the police for a crime he did not commit, which changes everything you are once you are arrested because society will label you as something you never were.\n",
    "2. The data of women at the beach equity in that whores and chines evidence negatively impacted their lives because, just because they are at the beach the network will classify them as whores and others which is not necessarily the case.  Based on the automasation and labeling with WordNet, the author describes how easy it is to label the images we have to train the networks, which would save time. These different network actors are just content with their realization, yet these works impact in negative ways on the lives of others such as women seen as put and dog mislabeled.\n",
    "3. The first factor to master is the label of each photo. Users should make sure that the photos are labeled exactly with the name of the data they describe. Especially avoid using heavy and dangerous terms like racist, insulting, injustice, prejudice. They should also remove the photos of people in the training photos for object recognition, to avoid confusion between species. Ameliorate the way to collect data which means collect data from a specifique target for the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
